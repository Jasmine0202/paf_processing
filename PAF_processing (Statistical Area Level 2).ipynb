{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df684e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Caculate PAF Function\n",
    "def PAF(area_name,value):\n",
    "    #Take the temperature of the highest frequency as the baseline statistics\n",
    "    df_zone_value = sa[str(area_name)]\n",
    "    area_code = ((df_zone_value-df_zone_value.min()).astype(int)).value_counts()\n",
    "    area_code = pd.concat([area_code,(area_code/area_code.sum()).apply('{:.2%}'.format)], axis=1)\n",
    "    area_code.index = area_code.index + df_zone_value.min()\n",
    "    area_code.columns = ['Counts','Percentage']\n",
    "    area_code = area_code.sort_index(ascending=False)\n",
    "    area_code = area_code.loc[area_code.index >= (result_step2[str(area_name)][value]).max()]\n",
    "    area_code = area_code.sort_index()\n",
    "    area_code = area_code.drop(columns=['Counts'])\n",
    "    area_code = area_code.reset_index()\n",
    "    area_code_min = area_code['index'].min()\n",
    "    area_code_min_max = area_code['index'].max()\n",
    "    index = []\n",
    "    percentage = [0 for x in range(int(area_code_min_max-area_code_min+1))]\n",
    "    for i in range(int(area_code_min_max-area_code_min+1)):\n",
    "        index.append(area_code_min)\n",
    "        area_code_min += 1\n",
    "    area_code_full = pd.DataFrame({'index':index,'Percentage':percentage})\n",
    "    area_code = pd.merge(area_code, area_code_full,how='right' ,on='index' )\n",
    "    area_code = area_code.sort_values(by='index').drop(columns=['Percentage_y']).reset_index(drop=True)\n",
    "    area_code = area_code.fillna(value='0%')\n",
    "    #PAF official\n",
    "    n = 1\n",
    "    PAF_numerator = []\n",
    "    for index, row in area_code.iterrows():\n",
    "        RR = math.pow(math.e,math.log(RR_dict[area_name]) * n)\n",
    "# Sensitivity analysis: 'Non-lineaer functions'\n",
    "#        RR = math.pow(math.e,(math.log(RR_dict[area_name]) + 1) * math.log(RR_dict[area_name]) * n)\n",
    "#        RR = math.pow(math.e,(math.log(RR_dict[area_name]) * math.log(RR_dict[area_name]) + math.log(RR_dict[area_name]) + 1) * math.log(RR_dict[area_name]) * n)\n",
    "        # Calculate PAF's numerator \n",
    "        numerator = (float(row[1].strip('%'))/100 * (RR-1))\n",
    "        PAF_numerator.append(numerator)\n",
    "        n += 1\n",
    "    # Calculate PAF\n",
    "    PAF = sum(PAF_numerator) / (sum(PAF_numerator)+1) * 100\n",
    "    return PAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a31ed60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X2003\n",
      "X2004\n",
      "X2005\n",
      "X2006\n",
      "X2007\n",
      "X2008\n",
      "X2009\n",
      "X2010\n",
      "X2011\n",
      "X2012\n",
      "X2013\n",
      "X2014\n",
      "X2015\n",
      "X2016\n",
      "X2017\n",
      "X2018\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')#Hide warnings to make the interface look better\n",
    "#(A) Load file\n",
    "# Step 1 data - daily mean temperature across 2,310 statistical areas (level 2) in Australia\n",
    "#get the path\n",
    "path = os.getcwd()\n",
    "#Get all of files name in the folder\n",
    "filenames = glob.glob(path+\"/Mean_*.csv\")\n",
    "#Loop files data and caculate PAF,then save to CSV, like: 'Mean_RCP85_2036_65PAF.csv'\n",
    "for filename in filenames:\n",
    "    df = pd.read_csv(filename)\n",
    "# Sensitivity analysis: alternative 'TMREDs'\n",
    "    df_step4 = pd.read_excel('MFT_Basline.xlsx')\n",
    "    df_step4.set_index(['Indicators'],inplace=True)\n",
    "# Sensitivity analyais: alternative 'Exposure-Response Functions'\n",
    "    df_RR = pd.read_csv('MH_RR.csv')\n",
    "    #Get RR Value\n",
    "    df_RR= df_RR.set_index(['ASGS_2016']).T.iloc[-1:].reset_index(drop=True)\n",
    "    df_RR = df_RR.loc[:,(df_RR!=0).any(axis=0)].T.reset_index()\n",
    "    RR_dict = dict(zip(df_RR['ASGS_2016'],df_RR[0]))\n",
    "    #Get the tmp area code\n",
    "    list_RR = df_RR['ASGS_2016'].tolist()\n",
    "    #Get all area zone code\n",
    "    df_list = list(map(int,list(df.columns)[1:]))\n",
    "    list_zone = [column for column in df_list if column in list_RR]\n",
    "    for x in list(RR_dict.keys()-list_zone):\n",
    "        del RR_dict[x]\n",
    "    df_PAF_MFT = pd.DataFrame(columns=([x for x in list_zone]))\n",
    "    n = 0\n",
    "    while ((df.index.max()+1) -n) != 0:\n",
    "        sa = df.iloc[n:n+365]\n",
    "        year = sa.reset_index(drop=True).iloc[:, 0][0][0:5]\n",
    "        sa = sa.drop(columns=['Unnamed: 0'])\n",
    "        Climate_Zone_MFT = df_step4.iloc[0:1]\n",
    "        Climate_Zone_MFT.index = ['MFT']\n",
    "        result_step2 = pd.concat([sa.describe(), Climate_Zone_MFT])\n",
    "        n += 365\n",
    "        print(year)\n",
    "        df_PAF = pd.DataFrame([[PAF(x,'MFT') for x in list_zone]])\n",
    "        df_PAF.columns = [x for x in list_zone]\n",
    "        df_PAF.index = [filename[-22:-4] + year + 'PAF']\n",
    "        df_PAF_MFT = pd.concat([df_PAF_MFT,df_PAF])\n",
    "    df_PAF_MFT.to_csv(filename[-22:-4]+'MHPAFRR.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ae7efd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
